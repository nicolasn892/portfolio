# Pipeline ETL (PySpark) — Exemplo

Descrição:
- Script de exemplo que lê CSVs, faz transformações e grava em formato Parquet particionado.

Como rodar local:
1. Tenha PySpark instalado (ou rode no Databricks).
2. Ajuste paths de input/output no script.
3. Rode: `spark-submit etl_spark.py` ou `python etl_spark.py` em ambiente PySpark.

Notas:
- Este script é uma base: documente dependências e parâmetros em produção.
